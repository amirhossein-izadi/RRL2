{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T05:09:33.663836Z",
     "iopub.status.busy": "2024-12-03T05:09:33.663209Z",
     "iopub.status.idle": "2024-12-03T05:09:33.670933Z",
     "shell.execute_reply": "2024-12-03T05:09:33.670104Z",
     "shell.execute_reply.started": "2024-12-03T05:09:33.663793Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/paramiko/pkey.py:82: CryptographyDeprecationWarning: TripleDES has been moved to cryptography.hazmat.decrepit.ciphers.algorithms.TripleDES and will be removed from this module in 48.0.0.\n",
      "  \"cipher\": algorithms.TripleDES,\n",
      "/usr/lib/python3/dist-packages/paramiko/transport.py:237: CryptographyDeprecationWarning: Blowfish has been moved to cryptography.hazmat.decrepit.ciphers.algorithms.Blowfish and will be removed from this module in 45.0.0.\n",
      "  \"class\": algorithms.Blowfish,\n",
      "/usr/lib/python3/dist-packages/paramiko/transport.py:261: CryptographyDeprecationWarning: TripleDES has been moved to cryptography.hazmat.decrepit.ciphers.algorithms.TripleDES and will be removed from this module in 48.0.0.\n",
      "  \"class\": algorithms.TripleDES,\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io, util, color\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "from skimage.metrics import structural_similarity as ssim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-12-03T05:09:36.310719Z",
     "iopub.status.busy": "2024-12-03T05:09:36.310386Z",
     "iopub.status.idle": "2024-12-03T05:09:36.327809Z",
     "shell.execute_reply": "2024-12-03T05:09:36.326982Z",
     "shell.execute_reply.started": "2024-12-03T05:09:36.310694Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, in_channels=1, out_channels=1):\n",
    "        super(UNet, self).__init__()\n",
    "        # Encoder\n",
    "        self.enc1 = self.conv_block(in_channels, 64)\n",
    "        self.enc2 = self.conv_block(64, 128)\n",
    "        self.enc3 = self.conv_block(128, 256)\n",
    "        self.enc4 = self.conv_block(256, 512)\n",
    "        # Bottleneck\n",
    "        self.bottleneck = self.conv_block(512, 1024)\n",
    "        # Decoder\n",
    "        self.up4 = nn.ConvTranspose2d(1024, 512, kernel_size=2, stride=2)\n",
    "        self.dec4 = self.conv_block(1024, 512)\n",
    "        self.up3 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)\n",
    "        self.dec3 = self.conv_block(512, 256)\n",
    "        self.up2 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n",
    "        self.dec2 = self.conv_block(256, 128)\n",
    "        self.up1 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
    "        self.dec1 = self.conv_block(128, 64)\n",
    "        # Final output\n",
    "        self.final = nn.Conv2d(64, out_channels, kernel_size=1)\n",
    "\n",
    "    def conv_block(self, in_channels, out_channels):\n",
    "        block = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, 3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        return block\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        e1 = self.enc1(x)\n",
    "        e2 = self.enc2(nn.MaxPool2d(2)(e1))\n",
    "        e3 = self.enc3(nn.MaxPool2d(2)(e2))\n",
    "        e4 = self.enc4(nn.MaxPool2d(2)(e3))\n",
    "        # Bottleneck\n",
    "        b = self.bottleneck(nn.MaxPool2d(2)(e4))\n",
    "        # Decoder\n",
    "        d4 = self.up4(b)\n",
    "        d4 = torch.cat((d4, e4), dim=1)\n",
    "        d4 = self.dec4(d4)\n",
    "        d3 = self.up3(d4)\n",
    "        d3 = torch.cat((d3, e3), dim=1)\n",
    "        d3 = self.dec3(d3)\n",
    "        d2 = self.up2(d3)\n",
    "        d2 = torch.cat((d2, e2), dim=1)\n",
    "        d2 = self.dec2(d2)\n",
    "        d1 = self.up1(d2)\n",
    "        d1 = torch.cat((d1, e1), dim=1)\n",
    "        d1 = self.dec1(d1)\n",
    "        # Output\n",
    "        out = self.final(d1)\n",
    "        return out, b  # Return bottleneck features\n",
    "\n",
    "# Custom Dataset with Multiple Domains\n",
    "class MultiDomainDataset(Dataset):\n",
    "    def __init__(self, image_paths, transform=None, mode='train'):\n",
    "        self.image_paths = image_paths\n",
    "        self.transform = transform\n",
    "        self.mode = mode\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = io.imread(self.image_paths[idx])\n",
    "        if len(image.shape) == 3:\n",
    "            image = color.rgb2gray(image)\n",
    "        image = (image * 255).astype(np.uint8)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        sample = {'clean': image}\n",
    "\n",
    "        if self.mode == 'train' or self.mode == 'val':\n",
    "            noise_type = random.choice(['gaussian', 'speckle'])\n",
    "            if self.mode == 'val':\n",
    "                noise_type = random.choice([noise_type, 'salt_pepper', 'salt_pepper'])\n",
    "                \n",
    "            if noise_type == 'gaussian':\n",
    "                noisy_image = util.random_noise(image, mode='gaussian', var=random.uniform(0.01, 0.05))\n",
    "            elif noise_type == 'salt_pepper':\n",
    "                noisy_image = util.random_noise(image, mode='s&p', amount=random.uniform(0.02, 0.1))\n",
    "            elif noise_type == 'speckle':\n",
    "                noisy_image = util.random_noise(image, mode='speckle', var=random.uniform(0.01, 0.05))\n",
    "            sample['noisy'] = torch.tensor(noisy_image, dtype=torch.float32)\n",
    "        elif self.mode == 'test':\n",
    "            # Use specific noise types based on test requirements\n",
    "            if idx % 4 == 0:\n",
    "                noise_type = random.choice(['gaussian', 'speckle'])\n",
    "            else:\n",
    "                noise_type = random.choice(['poisson', 'salt_pepper', 'salt_pepper', 'salt_pepper'])\n",
    "            if noise_type == 'gaussian':\n",
    "                noisy_image = util.random_noise(image, mode='gaussian', var=random.uniform(0.01, 0.05))\n",
    "            elif noise_type == 'speckle':\n",
    "                noisy_image = util.random_noise(image, mode='speckle', var=random.uniform(0.01, 0.05))\n",
    "            elif noise_type == 'poisson':\n",
    "                noisy_image = util.random_noise(image, mode='poisson')\n",
    "            elif noise_type == 'salt_pepper':\n",
    "                noisy_image = util.random_noise(image, mode='s&p', amount=random.uniform(0.04, 0.1))\n",
    "            sample['noisy'] = torch.tensor(noisy_image, dtype=torch.float32)\n",
    "\n",
    "        return sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T05:09:40.463780Z",
     "iopub.status.busy": "2024-12-03T05:09:40.463446Z",
     "iopub.status.idle": "2024-12-03T05:09:40.473340Z",
     "shell.execute_reply": "2024-12-03T05:09:40.472400Z",
     "shell.execute_reply.started": "2024-12-03T05:09:40.463753Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Custom Dataset with Multiple Domains\n",
    "class MultiDomainDataset(Dataset):\n",
    "    def __init__(self, image_paths, transform=None, mode='train'):\n",
    "        self.image_paths = image_paths\n",
    "        self.transform = transform\n",
    "        self.mode = mode\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = io.imread(self.image_paths[idx])\n",
    "        if len(image.shape) == 3:\n",
    "            image = color.rgb2gray(image)\n",
    "        image = (image * 255).astype(np.uint8)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        sample = {'clean': image}\n",
    "\n",
    "        if self.mode == 'train' or self.mode == 'val':\n",
    "            noise_type = random.choice(['gaussian', 'speckle'])\n",
    "            if self.mode == 'val':\n",
    "                noise_type = random.choice([noise_type, 'salt_pepper', 'salt_pepper'])\n",
    "                \n",
    "            if noise_type == 'gaussian':\n",
    "                noisy_image = util.random_noise(image, mode='gaussian', var=random.uniform(0.01, 0.05))\n",
    "            elif noise_type == 'salt_pepper':\n",
    "                noisy_image = util.random_noise(image, mode='s&p', amount=random.uniform(0.02, 0.05))\n",
    "            elif noise_type == 'speckle':\n",
    "                noisy_image = util.random_noise(image, mode='speckle', var=random.uniform(0.01, 0.05))\n",
    "            sample['noisy'] = torch.tensor(noisy_image, dtype=torch.float32)\n",
    "        elif self.mode == 'test':\n",
    "            # Use specific noise types based on test requirements\n",
    "            if idx % 4 == 0:\n",
    "                noise_type = random.choice(['gaussian', 'speckle'])\n",
    "            else:\n",
    "                noise_type = random.choice(['poisson', 'salt_pepper', 'salt_pepper', 'salt_pepper'])\n",
    "            if noise_type == 'gaussian':\n",
    "                noisy_image = util.random_noise(image, mode='gaussian', var=random.uniform(0.01, 0.05))\n",
    "            elif noise_type == 'speckle':\n",
    "                noisy_image = util.random_noise(image, mode='speckle', var=random.uniform(0.01, 0.05))\n",
    "            elif noise_type == 'poisson':\n",
    "                noisy_image = util.random_noise(image, mode='poisson')\n",
    "            elif noise_type == 'salt_pepper':\n",
    "                noisy_image = util.random_noise(image, mode='s&p', amount=random.uniform(0.04, 0.05))\n",
    "            sample['noisy'] = torch.tensor(noisy_image, dtype=torch.float32)\n",
    "\n",
    "        return sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T05:09:43.554496Z",
     "iopub.status.busy": "2024-12-03T05:09:43.553930Z",
     "iopub.status.idle": "2024-12-03T05:09:43.583022Z",
     "shell.execute_reply": "2024-12-03T05:09:43.582156Z",
     "shell.execute_reply.started": "2024-12-03T05:09:43.554463Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training images: 0\n",
      "Number of validation images: 0\n",
      "Number of testing images: 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import random\n",
    "\n",
    "# Load all image paths\n",
    "train_image_paths = glob.glob('/kaggle/input/berkeley-segmentation-dataset-500-bsds500/images/train/*.jpg')\n",
    "val_image_paths = glob.glob('/kaggle/input/berkeley-segmentation-dataset-500-bsds500/images/val/*.jpg')\n",
    "test_image_paths = glob.glob('/kaggle/input/berkeley-segmentation-dataset-500-bsds500/images/test/*.jpg')\n",
    "\n",
    "# Combine all images\n",
    "all_image_paths = train_image_paths + val_image_paths + test_image_paths\n",
    "\n",
    "# Shuffle the images\n",
    "random.shuffle(all_image_paths)\n",
    "\n",
    "# Split into train, val, and test\n",
    "train_image_paths = all_image_paths[:300]\n",
    "val_image_paths = all_image_paths[300:400]\n",
    "test_image_paths = all_image_paths[400:500]\n",
    "\n",
    "print(f\"Number of training images: {len(train_image_paths)}\")\n",
    "print(f\"Number of validation images: {len(val_image_paths)}\")\n",
    "print(f\"Number of testing images: {len(test_image_paths)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T05:09:47.384486Z",
     "iopub.status.busy": "2024-12-03T05:09:47.384118Z",
     "iopub.status.idle": "2024-12-03T05:09:47.390820Z",
     "shell.execute_reply": "2024-12-03T05:09:47.389805Z",
     "shell.execute_reply.started": "2024-12-03T05:09:47.384454Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "num_samples should be a positive integer value, but got num_samples=0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m test_dataset \u001b[38;5;241m=\u001b[39m MultiDomainDataset(test_image_paths, transform\u001b[38;5;241m=\u001b[39mtransform, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Create data loaders\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m \u001b[43mDataLoader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m val_loader \u001b[38;5;241m=\u001b[39m DataLoader(val_dataset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     16\u001b[0m test_loader \u001b[38;5;241m=\u001b[39m DataLoader(test_dataset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:376\u001b[0m, in \u001b[0;36mDataLoader.__init__\u001b[0;34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context, generator, prefetch_factor, persistent_workers, pin_memory_device)\u001b[0m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# map-style\u001b[39;00m\n\u001b[1;32m    375\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m shuffle:\n\u001b[0;32m--> 376\u001b[0m         sampler \u001b[38;5;241m=\u001b[39m \u001b[43mRandomSampler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgenerator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgenerator\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    377\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    378\u001b[0m         sampler \u001b[38;5;241m=\u001b[39m SequentialSampler(dataset)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/utils/data/sampler.py:164\u001b[0m, in \u001b[0;36mRandomSampler.__init__\u001b[0;34m(self, data_source, replacement, num_samples, generator)\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    160\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreplacement should be a boolean value, but got replacement=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreplacement\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    161\u001b[0m     )\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples, \u001b[38;5;28mint\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 164\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    165\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_samples should be a positive integer value, but got num_samples=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_samples\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    166\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: num_samples should be a positive integer value, but got num_samples=0"
     ]
    }
   ],
   "source": [
    "# # Data Augmentation\n",
    "# transform = transforms.Compose([\n",
    "#     transforms.ToPILImage(),\n",
    "#     transforms.Resize((256, 256)),\n",
    "#     transforms.ToTensor(),\n",
    "# ])\n",
    "\n",
    "# # Create datasets\n",
    "# train_dataset = MultiDomainDataset(train_image_paths, transform=transform, mode='train')\n",
    "# val_dataset = MultiDomainDataset(val_image_paths, transform=transform, mode='val')\n",
    "# test_dataset = MultiDomainDataset(test_image_paths, transform=transform, mode='test')\n",
    "\n",
    "# # Create data loaders\n",
    "# train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=0)\n",
    "# val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False, num_workers=0)\n",
    "# test_loader = DataLoader(test_dataset, batch_size=4, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T05:09:49.869930Z",
     "iopub.status.busy": "2024-12-03T05:09:49.869294Z",
     "iopub.status.idle": "2024-12-03T05:09:49.873819Z",
     "shell.execute_reply": "2024-12-03T05:09:49.872862Z",
     "shell.execute_reply.started": "2024-12-03T05:09:49.869896Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T05:09:52.084491Z",
     "iopub.status.busy": "2024-12-03T05:09:52.083927Z",
     "iopub.status.idle": "2024-12-03T05:09:53.996373Z",
     "shell.execute_reply": "2024-12-03T05:09:53.995481Z",
     "shell.execute_reply.started": "2024-12-03T05:09:52.084456Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# from torchmetrics.functional import structural_similarity_index_measure\n",
    "\n",
    "def reconstruction_loss(output, target):\n",
    "    # L1 Loss\n",
    "    l1_loss = nn.L1Loss()(output, target)\n",
    "\n",
    "    # SSIM Loss\n",
    "    output = output.clamp(0, 1)\n",
    "    target = target.clamp(0, 1)\n",
    "    ssim_loss = 1\n",
    "\n",
    "    # Weighted combination\n",
    "    return 0.7 * l1_loss + 0.3 * ssim_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T05:09:59.400097Z",
     "iopub.status.busy": "2024-12-03T05:09:59.399436Z",
     "iopub.status.idle": "2024-12-03T05:09:59.412176Z",
     "shell.execute_reply": "2024-12-03T05:09:59.411240Z",
     "shell.execute_reply.started": "2024-12-03T05:09:59.400064Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchmin2 import minimize\n",
    "\n",
    "def pairwise_distances(x, y, power=2, sum_dim=2):\n",
    "    n = x.size(0)\n",
    "    m = y.size(0)\n",
    "    d = x.size(1)\n",
    "\n",
    "    x = x.unsqueeze(1).expand(n,m,d)\n",
    "    y = y.unsqueeze(0).expand(n,m,d)\n",
    "    dist = torch.pow(x-y, power).sum(sum_dim)\n",
    "    return dist\n",
    "\n",
    "def StandardScaler(x,with_std=False):\n",
    "    mean = x.mean(0, keepdim=True)\n",
    "    std = x.std(0, unbiased=False, keepdim=True)\n",
    "    x = x- mean\n",
    "    if with_std:\n",
    "        x /= (std + 1e-10)\n",
    "    return x\n",
    "\n",
    "def H_Distance(FX,y,l,sigma=None,lamda=1e-2,device=torch.device('cpu')):   \n",
    "    if sigma is None:\n",
    "        pairwise_dist = torch.cdist(FX,FX,p=2)**2 \n",
    "        sigma = torch.median(pairwise_dist[pairwise_dist!=0])  \n",
    "    domain_label = torch.unique(l)\n",
    "    target_domain_idx = len(domain_label)-1\n",
    "    FXt,yt = FX[l==target_domain_idx],y[l==target_domain_idx]\n",
    "    nt = len(yt)\n",
    "    div = 0.0\n",
    "    for dl in domain_label[:-1]:\n",
    "        FXs,ys = FX[l==dl],y[l==dl]\n",
    "        ns = len(ys)\n",
    "        FXst,yst = torch.cat((FXs,FXt),dim=0),torch.cat((ys,yt),dim=0)\n",
    "        FXst_norm = torch.sum(FXst ** 2, axis = -1)\n",
    "        Kst = torch.exp(-(FXst_norm[:,None] + FXst_norm[None,:] - 2 * torch.matmul(FXst, FXst.t())) / sigma) * (yst[:,None]==yst)\n",
    "        def Obj(theta):\n",
    "            \"\"\"\n",
    "            Approximation of Hellinger distance\n",
    "            \"\"\"\n",
    "            div = 2. - (torch.mean(torch.exp(-torch.matmul(Kst[:ns],theta))) + torch.mean(torch.exp(torch.matmul(Kst[ns:],theta))))\n",
    "            reg = lamda * torch.matmul(theta,theta) \n",
    "            return -div + reg\n",
    "    \n",
    "        theta_0 = torch.zeros(ns+nt, device=device)\n",
    "        result = minimize(Obj,theta_0,method='l-bfgs')\n",
    "        theta_hat = result.x\n",
    "        div = div + 2. - (torch.mean(torch.exp(-torch.matmul(Kst[:ns],theta_hat))) + torch.mean(torch.exp(torch.matmul(Kst[ns:],theta_hat))))\n",
    "    return div     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-03T05:16:49.056875Z",
     "iopub.status.busy": "2024-12-03T05:16:49.056542Z",
     "iopub.status.idle": "2024-12-03T05:16:49.885479Z",
     "shell.execute_reply": "2024-12-03T05:16:49.884264Z",
     "shell.execute_reply.started": "2024-12-03T05:16:49.056847Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Proposed Model with Hellinger Distance...\n",
      "Epoch [1/4], Loss: 1.1509\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 45\u001b[0m\n\u001b[1;32m     43\u001b[0m optimizer_proposed \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(model_proposed\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-4\u001b[39m)\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining Proposed Model with Hellinger Distance...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 45\u001b[0m \u001b[43mtrain_proposed_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_proposed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer_proposed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlambda_h\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[9], line 17\u001b[0m, in \u001b[0;36mtrain_proposed_model\u001b[0;34m(model, train_loader, val_loader, optimizer, num_epochs, lambda_h)\u001b[0m\n\u001b[1;32m     15\u001b[0m noisy \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mconcat([noisy_train, noisy_val], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)[:, :\u001b[38;5;241m8\u001b[39m]\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Forward pass for training data\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m output, X \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnoisy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m X \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mreshape(X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     19\u001b[0m output_train \u001b[38;5;241m=\u001b[39m output[l \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[2], line 52\u001b[0m, in \u001b[0;36mUNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     50\u001b[0m d1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mup1(d2)\n\u001b[1;32m     51\u001b[0m d1 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((d1, e1), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 52\u001b[0m d1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdec1\u001b[49m\u001b[43m(\u001b[49m\u001b[43md1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m# Output\u001b[39;00m\n\u001b[1;32m     54\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinal(d1)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py:554\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 554\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/conv.py:549\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    538\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(\n\u001b[1;32m    539\u001b[0m         F\u001b[38;5;241m.\u001b[39mpad(\n\u001b[1;32m    540\u001b[0m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups,\n\u001b[1;32m    548\u001b[0m     )\n\u001b[0;32m--> 549\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    550\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\n\u001b[1;32m    551\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train Function for Proposed Model\n",
    "def train_proposed_model(model, train_loader, val_loader, optimizer, num_epochs=50, lambda_h=0.5):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        for i in range(1):\n",
    "            clean_train = torch.randn((4, 1, 256, 256)).to(device)\n",
    "            noisy_train = torch.randn((4, 1, 256, 256)).to(device)\n",
    "            noisy_val = torch.randn((4, 1, 256, 256)).to(device)\n",
    "\n",
    "            l = torch.concat([torch.zeros(noisy_train.shape[0]), torch.ones(noisy_val.shape[0])]).to(device)\n",
    "            noisy = torch.concat([noisy_train, noisy_val], dim=0)[:, :8]\n",
    "            # Forward pass for training data\n",
    "            output, X = model(noisy)\n",
    "            X = X.reshape(X.shape[0], -1)\n",
    "            output_train = output[l == 0]\n",
    "\n",
    "            loss_rec = reconstruction_loss(output_train, clean_train)\n",
    "            # Forward pass for validation data (no labels available, only compute latent)\n",
    "            y = torch.zeros((X.shape[0],)).to(device)\n",
    "            \n",
    "            # Compute Hellinger distance using PCA\n",
    "            loss_hellinger = H_Distance(X,y,l,sigma=None,lamda=1e-2,device=device)\n",
    "\n",
    "            # Total loss\n",
    "            loss = loss_rec + lambda_h * loss_hellinger\n",
    "\n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        avg_loss = epoch_loss / len(train_loader)\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}')\n",
    "\n",
    "# Instantiate and train\n",
    "model_proposed = UNet()\n",
    "optimizer_proposed = optim.Adam(model_proposed.parameters(), lr=1e-4)\n",
    "print(\"Training Proposed Model with Hellinger Distance...\")\n",
    "train_proposed_model(model_proposed, \" \", \" \", optimizer_proposed, num_epochs=4, lambda_h=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Train Function for Baseline Model\n",
    "def train_baseline_model(model, train_loader, optimizer, num_epochs=5):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        for train_batch in train_loader:\n",
    "            clean_train = train_batch['clean'].to(device)\n",
    "            noisy_train = train_batch['noisy'].to(device)\n",
    "\n",
    "            # Forward pass for training data\n",
    "            output_train, _ = model(noisy_train)\n",
    "            loss_rec = reconstruction_loss(output_train, clean_train)\n",
    "\n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss_rec.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss_rec.item()\n",
    "\n",
    "        avg_loss = epoch_loss / len(train_loader)\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}')\n",
    "\n",
    "\n",
    "model_baseline = UNet()\n",
    "optimizer_baseline = optim.Adam(model_baseline.parameters(), lr=1e-4)\n",
    "print(\"Training Baseline Model...\")\n",
    "train_baseline_model(model_baseline, train_loader, optimizer_baseline, num_epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Evaluation on Test Data\n",
    "def evaluate_model(model, test_loader):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    psnr_list = []\n",
    "    ssim_list = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            clean = batch['clean'].to(device)\n",
    "            noisy = batch['noisy'].to(device)\n",
    "\n",
    "            output, _ = model(noisy)\n",
    "\n",
    "            for i in range(clean.size(0)):\n",
    "                clean_img = clean[i].cpu().numpy().squeeze()\n",
    "                output_img = output[i].cpu().numpy().squeeze()\n",
    "                psnr_list.append(psnr(clean_img, output_img, data_range=clean_img.max() - clean_img.min()))\n",
    "                ssim_list.append(ssim(clean_img, output_img, data_range=clean_img.max() - clean_img.min()))\n",
    "\n",
    "    avg_psnr = np.mean(psnr_list)\n",
    "    avg_ssim = np.mean(ssim_list)\n",
    "    print(f'Average PSNR: {avg_psnr:.2f}, Average SSIM: {avg_ssim:.4f}')\n",
    "\n",
    "print(\"Evaluating Proposed Model...\")\n",
    "evaluate_model(model_proposed, test_loader)\n",
    "\n",
    "print(\"Evaluating Baseline Model...\")\n",
    "evaluate_model(model_baseline, test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Visualization for a test sample with salt and pepper noise\n",
    "def visualize_sample(model_proposed, model_baseline, sample_idx=0):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model_proposed.to(device)\n",
    "    model_baseline.to(device)\n",
    "    model_proposed.eval()\n",
    "    model_baseline.eval()\n",
    "\n",
    "    sample = test_dataset[sample_idx]\n",
    "    noisy_image = sample['noisy'].unsqueeze(0).to(device)\n",
    "    clean_image = sample['clean'].cpu().numpy().squeeze()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output_proposed, _ = model_proposed(noisy_image)\n",
    "        output_baseline, _ = model_baseline(noisy_image)\n",
    "\n",
    "    output_proposed = output_proposed.cpu().numpy().squeeze()\n",
    "    output_baseline = output_baseline.cpu().numpy().squeeze()\n",
    "\n",
    "    psnr_proposed = psnr(clean_image, output_proposed, data_range=clean_image.max() - clean_image.min())\n",
    "    ssim_proposed = ssim(clean_image, output_proposed, data_range=clean_image.max() - clean_image.min())\n",
    "    psnr_baseline = psnr(clean_image, output_baseline, data_range=clean_image.max() - clean_image.min())\n",
    "    ssim_baseline = ssim(clean_image, output_baseline, data_range=clean_image.max() - clean_image.min())\n",
    "\n",
    "    print(f'Proposed Model - PSNR: {psnr_proposed:.2f}, SSIM: {ssim_proposed:.4f}')\n",
    "    print(f'Baseline Model - PSNR: {psnr_baseline:.2f}, SSIM: {ssim_baseline:.4f}')\n",
    "\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    plt.subplot(1, 4, 1)\n",
    "    plt.title('Clean Image')\n",
    "    plt.imshow(clean_image, cmap='gray')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(1, 4, 2)\n",
    "    plt.title('Noisy Image (Salt & Pepper)')\n",
    "    plt.imshow(noisy_image.cpu().numpy().squeeze(), cmap='gray')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(1, 4, 3)\n",
    "    plt.title('Proposed Model Output')\n",
    "    plt.imshow(output_proposed, cmap='gray')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(1, 4, 4)\n",
    "    plt.title('Baseline Model Output')\n",
    "    plt.imshow(output_baseline, cmap='gray')\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(\"Visualizing a sample with salt and pepper noise...\")\n",
    "visualize_sample(model_proposed, model_baseline, sample_idx=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(\"Visualizing a sample with salt and pepper noise...\")\n",
    "visualize_sample(model_proposed, model_baseline, sample_idx=90)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(\"Visualizing a sample with salt and pepper noise...\")\n",
    "visualize_sample(model_proposed, model_baseline, sample_idx=60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(\"Visualizing a sample with salt and pepper noise...\")\n",
    "visualize_sample(model_proposed, model_baseline, sample_idx=33)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(\"Visualizing a sample with salt and pepper noise...\")\n",
    "visualize_sample(model_proposed, model_baseline, sample_idx=51)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from scipy.optimize import OptimizeResult\n",
    "from scipy.optimize.optimize import _status_message\n",
    "\n",
    "from .function import ScalarFunction\n",
    "from .line_search import strong_wolfe\n",
    "\n",
    "\n",
    "class HessianUpdateStrategy(ABC):\n",
    "    def __init__(self):\n",
    "        self.n_updates = 0\n",
    "\n",
    "    @abstractmethod\n",
    "    def solve(self, grad):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def _update(self, s, y, rho_inv):\n",
    "        pass\n",
    "\n",
    "    def update(self, s, y):\n",
    "        rho_inv = y.dot(s)\n",
    "        if rho_inv <= 1e-10:\n",
    "            # curvature is negative; do not update\n",
    "            return\n",
    "        self._update(s, y, rho_inv)\n",
    "        self.n_updates += 1\n",
    "\n",
    "\n",
    "class L_BFGS(HessianUpdateStrategy):\n",
    "    def __init__(self, x, history_size=100):\n",
    "        super().__init__()\n",
    "        self.y = []\n",
    "        self.s = []\n",
    "        self.rho = []\n",
    "        self.H_diag = 1.\n",
    "        self.alpha = x.new_empty(history_size)\n",
    "        self.history_size = history_size\n",
    "\n",
    "    def solve(self, grad):\n",
    "        mem_size = len(self.y)\n",
    "        d = grad.neg()\n",
    "        for i in reversed(range(mem_size)):\n",
    "            self.alpha[i] = self.s[i].dot(d) * self.rho[i]\n",
    "            d.add_(self.y[i], alpha=-self.alpha[i])\n",
    "        d.mul_(self.H_diag)\n",
    "        for i in range(mem_size):\n",
    "            beta_i = self.y[i].dot(d) * self.rho[i]\n",
    "            d.add_(self.s[i], alpha=self.alpha[i] - beta_i)\n",
    "\n",
    "        return d\n",
    "\n",
    "    def _update(self, s, y, rho_inv):\n",
    "        if len(self.y) == self.history_size:\n",
    "            self.y.pop(0)\n",
    "            self.s.pop(0)\n",
    "            self.rho.pop(0)\n",
    "        self.y.append(y)\n",
    "        self.s.append(s)\n",
    "        self.rho.append(rho_inv.reciprocal())\n",
    "        self.H_diag = rho_inv / y.dot(y)\n",
    "\n",
    "\n",
    "class BFGS(HessianUpdateStrategy):\n",
    "    def __init__(self, x, inverse=True):\n",
    "        super().__init__()\n",
    "        self.inverse = inverse\n",
    "        if inverse:\n",
    "            self.I = torch.eye(x.numel(), device=x.device, dtype=x.dtype)\n",
    "            self.H = self.I.clone()\n",
    "        else:\n",
    "            self.B = torch.eye(x.numel(), device=x.device, dtype=x.dtype)\n",
    "\n",
    "    def solve(self, grad):\n",
    "        if self.inverse:\n",
    "            return torch.matmul(self.H, grad.neg())\n",
    "        else:\n",
    "            return torch.cholesky_solve(grad.neg().unsqueeze(1),\n",
    "                                        torch.linalg.cholesky(self.B)).squeeze(1)\n",
    "\n",
    "    def _update(self, s, y, rho_inv):\n",
    "        rho = rho_inv.reciprocal()\n",
    "        if self.inverse:\n",
    "            if self.n_updates == 0:\n",
    "                self.H.mul_(rho_inv / y.dot(y))\n",
    "            R = torch.addr(self.I, s, y, alpha=-rho)\n",
    "            torch.addr(\n",
    "                torch.linalg.multi_dot((R, self.H, R.t())),\n",
    "                s, s, alpha=rho, out=self.H)\n",
    "        else:\n",
    "            if self.n_updates == 0:\n",
    "                self.B.mul_(rho * y.dot(y))\n",
    "            Bs = torch.mv(self.B, s)\n",
    "            self.B.addr_(y, y, alpha=rho)\n",
    "            self.B.addr_(Bs, Bs, alpha=-1./s.dot(Bs))\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def _minimize_bfgs_core(\n",
    "        fun, x0, lr=1., low_mem=False, history_size=100, inv_hess=True,\n",
    "        max_iter=None, line_search='strong-wolfe', gtol=1e-5, xtol=1e-9,\n",
    "        normp=float('inf'), callback=None, disp=0, return_all=False):\n",
    "    \"\"\"Minimize a multivariate function with BFGS or L-BFGS.\n",
    "\n",
    "    We choose from BFGS/L-BFGS with the `low_mem` argument.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    fun : callable\n",
    "        Scalar objective function to minimize\n",
    "    x0 : Tensor\n",
    "        Initialization point\n",
    "    lr : float\n",
    "        Step size for parameter updates. If using line search, this will be\n",
    "        used as the initial step size for the search.\n",
    "    low_mem : bool\n",
    "        Whether to use L-BFGS, the \"low memory\" variant of the BFGS algorithm.\n",
    "    history_size : int\n",
    "        History size for L-BFGS hessian estimates. Ignored if `low_mem=False`.\n",
    "    inv_hess : bool\n",
    "        Whether to parameterize the inverse hessian vs. the hessian with BFGS.\n",
    "        Ignored if `low_mem=True` (L-BFGS always parameterizes the inverse).\n",
    "    max_iter : int, optional\n",
    "        Maximum number of iterations to perform. Defaults to 200 * x0.numel()\n",
    "    line_search : str\n",
    "        Line search specifier. Currently the available options are\n",
    "        {'none', 'strong_wolfe'}.\n",
    "    gtol : float\n",
    "        Termination tolerance on 1st-order optimality (gradient norm).\n",
    "    xtol : float\n",
    "        Termination tolerance on function/parameter changes.\n",
    "    normp : Number or str\n",
    "        The norm type to use for termination conditions. Can be any value\n",
    "        supported by `torch.norm` p argument.\n",
    "    callback : callable, optional\n",
    "        Function to call after each iteration with the current parameter\n",
    "        state, e.g. ``callback(x)``.\n",
    "    disp : int or bool\n",
    "        Display (verbosity) level. Set to >0 to print status messages.\n",
    "    return_all : bool, optional\n",
    "        Set to True to return a list of the best solution at each of the\n",
    "        iterations.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    result : OptimizeResult\n",
    "        Result of the optimization routine.\n",
    "    \"\"\"\n",
    "    lr = float(lr)\n",
    "    disp = int(disp)\n",
    "    if max_iter is None:\n",
    "        max_iter = x0.numel() * 200\n",
    "    if low_mem and not inv_hess:\n",
    "        raise ValueError('inv_hess=False is not available for L-BFGS.')\n",
    "\n",
    "    # construct scalar objective function\n",
    "    sf = ScalarFunction(fun, x0.shape)\n",
    "    closure = sf.closure\n",
    "    if line_search == 'strong-wolfe':\n",
    "        dir_evaluate = sf.dir_evaluate\n",
    "\n",
    "    # compute initial f(x) and f'(x)\n",
    "    x = x0.detach().view(-1).clone(memory_format=torch.contiguous_format)\n",
    "    f, g, _, _ = closure(x)\n",
    "    if disp > 1:\n",
    "        print('initial fval: %0.4f' % f)\n",
    "    if return_all:\n",
    "        allvecs = [x]\n",
    "\n",
    "    # initial settings\n",
    "    if low_mem:\n",
    "        hess = L_BFGS(x, history_size)\n",
    "    else:\n",
    "        hess = BFGS(x, inv_hess)\n",
    "    d = g.neg()\n",
    "    t = min(1., g.norm(p=1).reciprocal()) * lr\n",
    "    n_iter = 0\n",
    "\n",
    "    # BFGS iterations\n",
    "    for n_iter in range(1, max_iter+1):\n",
    "\n",
    "        # ==================================\n",
    "        #   compute Quasi-Newton direction\n",
    "        # ==================================\n",
    "\n",
    "        if n_iter > 1:\n",
    "            d = hess.solve(g)\n",
    "\n",
    "        # directional derivative\n",
    "        gtd = g.dot(d)\n",
    "\n",
    "        # check if directional derivative is below tolerance\n",
    "        if gtd > -xtol:\n",
    "            warnflag = 4\n",
    "            msg = 'A non-descent direction was encountered.'\n",
    "            break\n",
    "\n",
    "        # ======================\n",
    "        #   update parameter\n",
    "        # ======================\n",
    "\n",
    "        if line_search == 'none':\n",
    "            # no line search, move with fixed-step\n",
    "            x_new = x + d.mul(t)\n",
    "            f_new, g_new, _, _ = closure(x_new)\n",
    "        elif line_search == 'strong-wolfe':\n",
    "            #  Determine step size via strong-wolfe line search\n",
    "            f_new, g_new, t, ls_evals = \\\n",
    "                strong_wolfe(dir_evaluate, x, t, d, f, g, gtd)\n",
    "            x_new = x + d.mul(t)\n",
    "        else:\n",
    "            raise ValueError('invalid line_search option {}.'.format(line_search))\n",
    "\n",
    "        if disp > 1:\n",
    "            print('iter %3d - fval: %0.4f' % (n_iter, f_new))\n",
    "        if return_all:\n",
    "            allvecs.append(x_new)\n",
    "        if callback is not None:\n",
    "            callback(x_new)\n",
    "\n",
    "        # ================================\n",
    "        #   update hessian approximation\n",
    "        # ================================\n",
    "\n",
    "        s = x_new.sub(x)\n",
    "        y = g_new.sub(g)\n",
    "\n",
    "        hess.update(s, y)\n",
    "\n",
    "        # =========================================\n",
    "        #   check conditions and update buffers\n",
    "        # =========================================\n",
    "\n",
    "        # convergence by insufficient progress\n",
    "        if (s.norm(p=normp) <= xtol) | ((f_new - f).abs() <= xtol):\n",
    "            warnflag = 0\n",
    "            msg = _status_message['success']\n",
    "            break\n",
    "\n",
    "        # update state\n",
    "        f[...] = f_new\n",
    "        x.copy_(x_new)\n",
    "        g.copy_(g_new)\n",
    "        t = lr\n",
    "\n",
    "        # convergence by 1st-order optimality\n",
    "        if g.norm(p=normp) <= gtol:\n",
    "            warnflag = 0\n",
    "            msg = _status_message['success']\n",
    "            break\n",
    "\n",
    "        # precision loss; exit\n",
    "        if ~f.isfinite():\n",
    "            warnflag = 2\n",
    "            msg = _status_message['pr_loss']\n",
    "            break\n",
    "\n",
    "    else:\n",
    "        # if we get to the end, the maximum num. iterations was reached\n",
    "        warnflag = 1\n",
    "        msg = _status_message['maxiter']\n",
    "\n",
    "    if disp:\n",
    "        print(msg)\n",
    "        print(\"         Current function value: %f\" % f)\n",
    "        print(\"         Iterations: %d\" % n_iter)\n",
    "        print(\"         Function evaluations: %d\" % sf.nfev)\n",
    "    result = OptimizeResult(fun=f, x=x.view_as(x0), grad=g.view_as(x0),\n",
    "                            status=warnflag, success=(warnflag==0),\n",
    "                            message=msg, nit=n_iter, nfev=sf.nfev)\n",
    "    if not low_mem:\n",
    "        if inv_hess:\n",
    "            result['hess_inv'] = hess.H.view(2 * x0.shape)\n",
    "        else:\n",
    "            result['hess'] = hess.B.view(2 * x0.shape)\n",
    "    if return_all:\n",
    "        result['allvecs'] = allvecs\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def _minimize_bfgs(\n",
    "        fun, x0, lr=1., inv_hess=True, max_iter=None,\n",
    "        line_search='strong-wolfe', gtol=1e-5, xtol=1e-9,\n",
    "        normp=float('inf'), callback=None, disp=0, return_all=False):\n",
    "    \"\"\"Minimize a multivariate function with BFGS\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    fun : callable\n",
    "        Scalar objective function to minimize.\n",
    "    x0 : Tensor\n",
    "        Initialization point.\n",
    "    lr : float\n",
    "        Step size for parameter updates. If using line search, this will be\n",
    "        used as the initial step size for the search.\n",
    "    inv_hess : bool\n",
    "        Whether to parameterize the inverse hessian vs. the hessian with BFGS.\n",
    "    max_iter : int, optional\n",
    "        Maximum number of iterations to perform. Defaults to\n",
    "        ``200 * x0.numel()``.\n",
    "    line_search : str\n",
    "        Line search specifier. Currently the available options are\n",
    "        {'none', 'strong_wolfe'}.\n",
    "    gtol : float\n",
    "        Termination tolerance on 1st-order optimality (gradient norm).\n",
    "    xtol : float\n",
    "        Termination tolerance on function/parameter changes.\n",
    "    normp : Number or str\n",
    "        The norm type to use for termination conditions. Can be any value\n",
    "        supported by :func:`torch.norm`.\n",
    "    callback : callable, optional\n",
    "        Function to call after each iteration with the current parameter\n",
    "        state, e.g. ``callback(x)``.\n",
    "    disp : int or bool\n",
    "        Display (verbosity) level. Set to >0 to print status messages.\n",
    "    return_all : bool, optional\n",
    "        Set to True to return a list of the best solution at each of the\n",
    "        iterations.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    result : OptimizeResult\n",
    "        Result of the optimization routine.\n",
    "    \"\"\"\n",
    "    return _minimize_bfgs_core(\n",
    "        fun, x0, lr, low_mem=False, inv_hess=inv_hess, max_iter=max_iter,\n",
    "        line_search=line_search, gtol=gtol, xtol=xtol,\n",
    "        normp=normp, callback=callback, disp=disp, return_all=return_all)\n",
    "\n",
    "\n",
    "def _minimize_lbfgs(\n",
    "        fun, x0, lr=1., history_size=100, max_iter=None,\n",
    "        line_search='strong-wolfe', gtol=1e-5, xtol=1e-9,\n",
    "        normp=float('inf'), callback=None, disp=0, return_all=False):\n",
    "    \"\"\"Minimize a multivariate function with L-BFGS\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    fun : callable\n",
    "        Scalar objective function to minimize.\n",
    "    x0 : Tensor\n",
    "        Initialization point.\n",
    "    lr : float\n",
    "        Step size for parameter updates. If using line search, this will be\n",
    "        used as the initial step size for the search.\n",
    "    history_size : int\n",
    "        History size for L-BFGS hessian estimates.\n",
    "    max_iter : int, optional\n",
    "        Maximum number of iterations to perform. Defaults to\n",
    "        ``200 * x0.numel()``.\n",
    "    line_search : str\n",
    "        Line search specifier. Currently the available options are\n",
    "        {'none', 'strong_wolfe'}.\n",
    "    gtol : float\n",
    "        Termination tolerance on 1st-order optimality (gradient norm).\n",
    "    xtol : float\n",
    "        Termination tolerance on function/parameter changes.\n",
    "    normp : Number or str\n",
    "        The norm type to use for termination conditions. Can be any value\n",
    "        supported by :func:`torch.norm`.\n",
    "    callback : callable, optional\n",
    "        Function to call after each iteration with the current parameter\n",
    "        state, e.g. ``callback(x)``.\n",
    "    disp : int or bool\n",
    "        Display (verbosity) level. Set to >0 to print status messages.\n",
    "    return_all : bool, optional\n",
    "        Set to True to return a list of the best solution at each of the\n",
    "        iterations.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    result : OptimizeResult\n",
    "        Result of the optimization routine.\n",
    "    \"\"\"\n",
    "    return _minimize_bfgs_core(\n",
    "        fun, x0, lr, low_mem=True, history_size=history_size,\n",
    "        max_iter=max_iter, line_search=line_search, gtol=gtol, xtol=xtol,\n",
    "        normp=normp, callback=callback, disp=disp, return_all=return_all)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 916809,
     "sourceId": 1553396,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
